{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**O script está organizado de acordo com o planejamento que levou ao modelo de classificação selecionado**"
      ],
      "metadata": {
        "id": "-Fscl7Oz7dcI"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jG9RMC6kjwKB"
      },
      "source": [
        "**3. PROCESSAMENTO/TRATAMENTO DE DADOS**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2X_aL-yOFNDF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd #biblioteca pandas\n",
        "import numpy as np #biblioteca numpy\n",
        "import matplotlib.pyplot as plt #biblioteca matplotlib\n",
        "%matplotlib inline\n",
        "import seaborn as sns #biblioteca seaborn\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score #matriz de confusão\n",
        "from sklearn.tree import DecisionTreeClassifier #Árvore de Decisão\n",
        "from sklearn.ensemble import RandomForestClassifier #Floresta randômica\n",
        "from sklearn.model_selection import GridSearchCV #otimização de parâmetros com validação cruzada\n",
        "from sklearn.metrics import accuracy_score, classification_report #dados matriz de confusão\n",
        "from sklearn.preprocessing import StandardScaler #padronização dos dados\n",
        "from sklearn.model_selection import train_test_split #geração das bases de dados de treinamento e de teste\n",
        "from sklearn.metrics import ConfusionMatrixDisplay #Matriz de confusão\n",
        "from sklearn.neural_network import MLPClassifier #redes neurais\n",
        "from sklearn import neural_network #Redes neurais artificiais\n",
        "from sklearn.ensemble import AdaBoostClassifier #adaboost\n",
        "from sklearn import datasets, tree #Árvore de decisão\n",
        "from sklearn.ensemble import GradientBoostingClassifier #gradient boosting\n",
        "\n",
        "from scipy.stats import shapiro #teste de hipóteses Shapiro-Wilk\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor #VIF\n",
        "from imblearn.under_sampling import TomekLinks #técnica de subamostragem\n",
        "import statsmodels.api as sm #teste de hipóteses ANOVA\n",
        "from statsmodels.formula.api import ols #teste de hipóteses ANOVA\n",
        "from statsmodels.stats.multicomp import pairwise_tukeyhsd #teste de hipóteses de Tukey"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZr3qPnzcqfA"
      },
      "outputs": [],
      "source": [
        "#Obter as bases de dados WineQuality: RedWine e WhiteWine\n",
        "\n",
        "red = pd.read_csv('/content/WineQuality-RedWine.csv')\n",
        "white = pd.read_csv('/content/WineQuality-WhiteWine.csv')\n",
        "nomes_port = {'fixed acidity': 'acidez fixa', 'volatile acidity': 'acidez volátil', 'citric acid': 'teor de ácido cítrico', \n",
        "                          'residual sugar': 'teor de açúcares residuais', 'chlorides': 'teor de cloretos', 'free sulfur dioxide': 'teor de SO2 livre', \n",
        "                          'total sulfur dioxide': 'teor de SO2 total', 'density': 'densidade', 'sulphates': 'teor de sulfatos',\n",
        "                          'alcohol': 'teor de álcool', 'quality': 'qualidade'}\n",
        "red = red.rename(columns=nomes_port)\n",
        "white = white.rename(columns=nomes_port)\n",
        "\n",
        "print('Dimensões da base de dados dos vinhos tintos: ', red.shape)\n",
        "print('Dimensões da base de dados dos vinhos brancos: ', white.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H7vAbA1xu7Y0"
      },
      "outputs": [],
      "source": [
        "#Configurando a apresentação dos dataframes\n",
        "\n",
        "pd.set_option('display.min_rows', 10)\n",
        "pd.set_option('display.precision', 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vs7ViHmxaJ1k"
      },
      "outputs": [],
      "source": [
        "#Apresentação de parte do dataframe red\n",
        "\n",
        "red"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SltVTvpHDmsY"
      },
      "outputs": [],
      "source": [
        "#Apresentação de parte do dataframe white\n",
        "\n",
        "white"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rptcRLRDHf5G"
      },
      "outputs": [],
      "source": [
        "#União dos dataframes red e white formando o dataframe vinhos\n",
        "\n",
        "vinhos = pd.concat([red, white], ignore_index=1)\n",
        "vinhos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u9q7AFG_9DNz"
      },
      "outputs": [],
      "source": [
        "#Verificação de dados faltantes em vinhos\n",
        "\n",
        "print(vinhos.isnull().sum(), '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QOPfhhSvxp1D"
      },
      "outputs": [],
      "source": [
        "#Verificação de outros tipos de dados\n",
        "\n",
        "vinhos.select_dtypes(exclude='number')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ANÁLISE E EXPLORAÇÃO DOS DADOS**"
      ],
      "metadata": {
        "id": "Q-0wDF1CFb4W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oM0F0o0NHcXE"
      },
      "outputs": [],
      "source": [
        "# Tabela com os dados descritivos dos atributos preditores de vinhos\n",
        "\n",
        "vinhos.iloc[:, 0:11].describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fzQ1-ydE458h"
      },
      "outputs": [],
      "source": [
        "#Mostrar os boxplots dos atributos preditores de vinhos\n",
        "\n",
        "fig, bp = plt.subplots(1, 6, figsize=(20, 8))\n",
        "bp[0].boxplot(vinhos.iloc[:,0]); bp[0].set_title('acidez fixa')\n",
        "bp[1].boxplot(vinhos.iloc[:,1]); bp[1].set_title('acidez volátil')\n",
        "bp[2].boxplot(vinhos.iloc[:,2]); bp[2].set_title('teor de ácido cítrico')\n",
        "bp[3].boxplot(vinhos.iloc[:,3]); bp[3].set_title('teor de açúcar residual')\n",
        "bp[4].boxplot(vinhos.iloc[:,4]); bp[4].set_title('teor de cloretos')\n",
        "bp[5].boxplot(vinhos.iloc[:,5]); bp[5].set_title('teor de SO2 livre')\n",
        "\n",
        "fig, bp2 = plt.subplots(1, 5, figsize=(20, 8))\n",
        "bp2[0].boxplot(vinhos.iloc[:,6]); bp2[0].set_title('teor de SO2 total')\n",
        "bp2[1].boxplot(vinhos.iloc[:,7]); bp2[1].set_title('densidade')\n",
        "bp2[2].boxplot(vinhos.iloc[:,8]); bp2[2].set_title('pH')\n",
        "bp2[3].boxplot(vinhos.iloc[:,9]); bp2[3].set_title('teor de sulfatos')\n",
        "bp2[4].boxplot(vinhos.iloc[:,10]); bp2[4].set_title('teor de álcool')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "grN1WGJlp1oz"
      },
      "outputs": [],
      "source": [
        "#Mostrar a matriz de dispersão dos dados dos atributos da base de dados vinhos\n",
        "\n",
        "sns.pairplot(vinhos.iloc[:,0:11])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IRhsPBbL28Yu"
      },
      "outputs": [],
      "source": [
        "#Exclusão de registros com outliers (matriz de dispersão de pontos)\n",
        "\n",
        "vinhos.drop(vinhos[vinhos['acidez fixa'] >= 14].index, inplace = True)\n",
        "vinhos.drop(vinhos[vinhos['acidez fixa'] <= 4.5].index, inplace = True)\n",
        "vinhos.drop(vinhos[vinhos['acidez volátil'] >= 1.23].index, inplace = True)\n",
        "vinhos.drop(vinhos[vinhos['teor de ácido cítrico'] >= 0.78].index, inplace=True)\n",
        "vinhos.drop(vinhos[vinhos['teor de açúcares residuais'] >= 24].index, inplace=True)\n",
        "vinhos.drop(vinhos[vinhos['teor de cloretos'] >= 0.3].index, inplace=True)\n",
        "vinhos.drop(vinhos[vinhos['teor de SO2 livre'] >= 125].index, inplace=True)\n",
        "vinhos.drop(vinhos[vinhos['teor de SO2 total'] >= 280].index, inplace=True)\n",
        "vinhos.drop(vinhos[vinhos['densidade'] >= 1.007].index, inplace=True)\n",
        "vinhos.drop(vinhos[vinhos['pH'] >= 3.9].index, inplace=True)\n",
        "vinhos.drop(vinhos[vinhos['teor de sulfatos'] >= 1.25].index, inplace=True)\n",
        "vinhos.drop(vinhos[vinhos['teor de álcool'] >= 14.0].index, inplace=True)\n",
        "\n",
        "vinhos.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Geração de gráficos de dispersão de pontos comparando cada atributo preditor com o atributo classe\n",
        "\n",
        "fig, gd = plt.subplots(1, 6, figsize=(20, 8))\n",
        "gd[0].scatter(vinhos['qualidade'], vinhos['acidez fixa'], color='skyblue'); gd[0].set_title('qualid. x acidez fixa')\n",
        "gd[1].scatter(vinhos['qualidade'], vinhos['acidez volátil'], color='skyblue'); gd[1].set_title('qualid. x acidez volátil')\n",
        "gd[2].scatter(vinhos['qualidade'], vinhos['teor de ácido cítrico'], color='skyblue'); gd[2].set_title('qualid. x teor ácido cítrico')\n",
        "gd[3].scatter(vinhos['qualidade'], vinhos['teor de açúcares residuais'], color='skyblue'); gd[3].set_title('qualid. x teor açúcares residuais')\n",
        "gd[4].scatter(vinhos['qualidade'], vinhos['teor de cloretos'], color='skyblue'); gd[4].set_title('qualid. x teor cloretos')\n",
        "gd[5].scatter(vinhos['qualidade'], vinhos['teor de SO2 livre'], color='skyblue'); gd[5].set_title('qualid. x teor de SO2 livre')\n",
        "\n",
        "fig, gd2 = plt.subplots(1, 5, figsize=(20, 8))\n",
        "gd2[0].scatter(vinhos['qualidade'], vinhos['teor de SO2 total'], color='skyblue'); gd2[0].set_title('qualid. x teor de SO2 total')\n",
        "gd2[1].scatter(vinhos['qualidade'], vinhos['densidade'], color='skyblue'); gd2[1].set_title('qualid. x densidade')\n",
        "gd2[2].scatter(vinhos['qualidade'], vinhos['pH'], color='skyblue'); gd2[2].set_title('qualid. x pH')\n",
        "gd2[3].scatter(vinhos['qualidade'], vinhos['teor de sulfatos'], color='skyblue'); gd2[3].set_title('qualid. x teor sulfatos')\n",
        "gd2[4].scatter(vinhos['qualidade'], vinhos['teor de álcool'], color='skyblue'); gd2[4].set_title('qualid. x teor de álcool')"
      ],
      "metadata": {
        "id": "Ydt9BbN5HXUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Pmfff5b6RFv"
      },
      "outputs": [],
      "source": [
        "# Matriz de correlação de Pearson\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plot = sns.heatmap(vinhos.iloc[:,0:11].corr(), annot=True)\n",
        "plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sI_6pjMZTKRT"
      },
      "outputs": [],
      "source": [
        "# Avaliação da multicolinearidade\n",
        "\n",
        "nc = []\n",
        "for i in range(11):\n",
        "  nc.append(variance_inflation_factor(vinhos.iloc[:,0:11].values, i))\n",
        "\n",
        "multic = pd.DataFrame(zip(vinhos.iloc[:,0:11].columns, nc), columns=['Atributos preditores', 'VIF'])\n",
        "print(multic, '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NeHlsMNYEjBc"
      },
      "outputs": [],
      "source": [
        "#Dividir a base de dados vinhos em atributos preditores e atributo classe\n",
        "\n",
        "X_vinhos = vinhos.iloc[:, 0:11].values\n",
        "y_vinhos = vinhos.iloc[:, 11].values\n",
        "print('A base de dados preditora tem as seguintes dimensões: ', X_vinhos.shape)\n",
        "print('A base de dados de teste tem as seguintes dimensões: ', y_vinhos.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gnVRWwQltfvw"
      },
      "outputs": [],
      "source": [
        "#Padronização dos dados de X_vinhos\n",
        "\n",
        "pad = StandardScaler()\n",
        "X_vinhos_p = pad.fit_transform(X_vinhos)\n",
        "X_vinhos_p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VVQQIF3Tu_QS"
      },
      "outputs": [],
      "source": [
        "#Comprovação da padronização dos dados da base de dados X_vinhos\n",
        "\n",
        "print((np.mean(X_vinhos_p, axis=0)), '\\n')\n",
        "print(np.std(X_vinhos_p, axis=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jq7TVfd2lD3q"
      },
      "outputs": [],
      "source": [
        "#Verificar a frequência das categorias do atributo classe\n",
        "\n",
        "print(np.unique(y_vinhos, return_counts=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A3Dvxmqh-pqK"
      },
      "outputs": [],
      "source": [
        "#Gráfico de barras dos valores do atributo classe\n",
        "\n",
        "y_vinhos_df = pd.DataFrame(y_vinhos)\n",
        "sns.catplot(x = 0, kind = 'count', data = y_vinhos_df, palette='Oranges')\n",
        "plt.ylabel(\"Frequência\")\n",
        "plt.xlabel(\"Categorias\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ccgZIUUOVFtD"
      },
      "outputs": [],
      "source": [
        "#Distribuir os dados do atributo classe em novas categorias\n",
        "\n",
        "for i in range(len(y_vinhos)):\n",
        "  if y_vinhos[i] <= 6:\n",
        "    y_vinhos[i] = 1\n",
        "  if y_vinhos[i] > 6:\n",
        "    y_vinhos[i] = 2\n",
        "  \n",
        "print(np.unique(y_vinhos, return_counts=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6rIahQWOWTXV"
      },
      "outputs": [],
      "source": [
        "#Gráfico de barras dos valores do atributo classe após a formação das novas categorias\n",
        "\n",
        "y_vinhos_df2 = pd.DataFrame(y_vinhos)\n",
        "sns.catplot(x = 0, kind = 'count', data = y_vinhos_df2, palette='Oranges')\n",
        "plt.ylabel(\"Frequência\")\n",
        "plt.xlabel(\"Categoria\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JfCHf89Cxeat"
      },
      "outputs": [],
      "source": [
        "#Subamostragem TomekLinks\n",
        "\n",
        "tl = TomekLinks(sampling_strategy='majority')\n",
        "X_vinhos_p_sub, y_vinhos_sub = tl.fit_resample(X_vinhos_p, y_vinhos)\n",
        "print(X_vinhos_p_sub.shape, y_vinhos_sub.shape)\n",
        "print(np.unique(y_vinhos_sub, return_counts=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "562V8td8EBpy"
      },
      "outputs": [],
      "source": [
        "#Apresentar o gráfico de coordenadas paralelas\n",
        "\n",
        "X_df = pd.DataFrame(X_vinhos_p_sub)\n",
        "y_df = pd.DataFrame(y_vinhos_sub)\n",
        "vinhos_par = pd.concat([X_df, y_df], axis = 1) \n",
        "\n",
        "vinhos_par.columns = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11']\n",
        "\n",
        "ax3 = pd.plotting.parallel_coordinates(vinhos_par, '11', color=('SteelBlue', 'Yellow', 'Chocolate'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0N_0qiNKtNyb"
      },
      "source": [
        "**CRIAÇÃO DE MODELOS DE MACHINE LEARNING**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QDQLtfQ-DJmo"
      },
      "outputs": [],
      "source": [
        "# Criação da base de dados de treinamento e de teste\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_vinhos_p_sub, y_vinhos_sub, test_size = 0.30, random_state = 10)\n",
        "print('As dimensões da base de dados de treinamento (atributos preditores) são: ', X_train.shape)\n",
        "print('As dimensões da base de dados de teste (atributos preditores) são: ', X_test.shape)\n",
        "print('As dimensões da base de dados de treinamento (atributo classe) são: ', y_train.shape)\n",
        "print('As dimensões da base de dados de teste (atributo classe) são: ', y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EIgWd2G5ua4G"
      },
      "outputs": [],
      "source": [
        "#GridSearchCV - Árvore de Decisão\n",
        "\n",
        "param_dict = {'criterion': ['gini', 'entropy'], \n",
        "              'max_depth': range(1, 10),\n",
        "              'min_samples_split': range(1, 10),\n",
        "              'min_samples_leaf': range(1, 5)}\n",
        "\n",
        "grid = GridSearchCV(DecisionTreeClassifier(), param_grid=param_dict, cv = 10, verbose = 1, n_jobs = -1)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "print('\\n', '\\n', 'Os melhores parâmetros são ', grid.best_params_)\n",
        "print('A acurária é igual a ', grid.best_score_, '\\n', '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EThOiITo9soo"
      },
      "outputs": [],
      "source": [
        "#Cálculo das métricas do modelo de árvore de decisão\n",
        "\n",
        "ac_trein = []\n",
        "ac_prev = []\n",
        "prec_cat1 = []\n",
        "prec_cat2 = []\n",
        "rec_cat1 = []\n",
        "rec_cat2 = []\n",
        "f1_cat1 = []\n",
        "f1_cat2 = []\n",
        "\n",
        "for i in range(0,100):\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X_vinhos_p_sub, y_vinhos_sub, test_size = 0.30)\n",
        "  arv_dec = DecisionTreeClassifier(criterion = 'gini', max_depth = 9, min_samples_leaf = 1, min_samples_split = 2)\n",
        "  arv_dec = arv_dec.fit(X_train, y_train)\n",
        "  y_pred = arv_dec.predict(X_test)\n",
        "  cm = confusion_matrix(y_test, y_pred)\n",
        "  ac_trein.append(arv_dec.score(X_train, y_train))\n",
        "  ac_prev.append(accuracy_score(y_test, y_pred))\n",
        "  prec_cat1.append(cm[0, 0]/(cm[0, 0] + cm[1, 0]))\n",
        "  prec_cat2.append(cm[1, 1]/(cm[1, 1] + cm[0, 1]))\n",
        "  rec_cat1.append(cm[0, 0]/(cm[0, 0] + cm[0, 1]))\n",
        "  rec_cat2.append(cm[1, 1]/(cm[1, 1] + cm[1, 0]))\n",
        "  f1_cat1.append(2*((cm[0, 0]/(cm[0, 0] + cm[1, 0])) * (cm[0, 0]/(cm[0, 0] + cm[0, 1])))/\n",
        "                 ((cm[0, 0]/(cm[0, 0] + cm[1, 0])) + (cm[0, 0]/(cm[0, 0] + cm[0, 1]))))\n",
        "  f1_cat2.append(2*((cm[1, 1]/(cm[1, 1] + cm[0, 1])) * (cm[1, 1]/(cm[1, 1] + cm[1, 0])))/\n",
        "                 ((cm[1, 1]/(cm[1, 1] + cm[0, 1])) + (cm[1, 1]/(cm[1, 1] + cm[1, 0]))))\n",
        "\n",
        "print('Acurácia de treinamento:', round(np.mean(ac_trein), 3), '+/-', round(np.std(ac_trein), 3))\n",
        "print('Acurácia de previsão:', round(np.mean(ac_prev), 3), '+/-', round(np.std(ac_prev), 3))\n",
        "print('Precisão da categoria 1:', round(np.mean(prec_cat1), 3), '+/-', round(np.std(prec_cat1), 3))\n",
        "print('Precisão da categoria 2:', round(np.mean(prec_cat2), 3), '+/-', round(np.std(prec_cat2), 3))\n",
        "print('Recall da categoria 1:', round(np.mean(rec_cat1), 3), '+/-', round(np.std(rec_cat1), 3))\n",
        "print('Recall da categoria 2:', round(np.mean(rec_cat2), 3), '+/-', round(np.std(rec_cat2), 3))\n",
        "print('f1-score da categoria 1:', round(np.mean(f1_cat1), 3), '+/-', round(np.std(f1_cat1), 3))\n",
        "print('f1-score da categoria 2:', round(np.mean(f1_cat2), 3), '+/-', round(np.std(f1_cat2), 3))\n",
        "\n",
        "ac_prev_arv = np.copy(ac_prev)\n",
        "prec_cat1_arv = np.copy(prec_cat1)\n",
        "prec_cat2_arv = np.copy(prec_cat2)\n",
        "rec_cat1_arv = np.copy(rec_cat1)\n",
        "rec_cat2_arv = np.copy(rec_cat2)\n",
        "f1_cat1_arv = np.copy(f1_cat1)\n",
        "f1_cat2_arv = np.copy(f1_cat2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Histogramas - árvore de decisão\n",
        "\n",
        "fig, hi = plt.subplots(1, 4, figsize=(20, 8))\n",
        "hi[0].hist(x=ac_prev_arv, bins='auto', color='lightblue', alpha=0.9, rwidth=0.85); hi[0].set_title('acurácia de previsão')\n",
        "hi[1].hist(x=prec_cat1_arv, bins='auto', color='lightblue', alpha=0.9, rwidth=0.85); hi[1].set_title('precisão categoria 1')\n",
        "hi[2].hist(x=prec_cat2_arv, bins='auto', color='lightblue', alpha=0.9, rwidth=0.85); hi[2].set_title('precisão categoria 2')\n",
        "hi[3].hist(x=rec_cat1_arv, bins='auto', color='lightblue', alpha=0.9, rwidth=0.85); hi[3].set_title('recall categoria 1')\n",
        "\n",
        "fig, hi2 = plt.subplots(1, 3, figsize=(20, 8))\n",
        "hi2[0].hist(x=rec_cat2_arv, bins='auto', color='lightblue', alpha=0.9, rwidth=0.85); hi2[0].set_title('recall categoria 2')\n",
        "hi2[1].hist(x=f1_cat1_arv, bins='auto', color='lightblue', alpha=0.9, rwidth=0.85); hi2[1].set_title('f1-score categoria 1')\n",
        "hi2[2].hist(x=f1_cat2_arv, bins='auto', color='lightblue', alpha=0.9, rwidth=0.85); hi2[2].set_title('f1-score categoria 2')"
      ],
      "metadata": {
        "id": "gUzepggrz10p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Aplicação do teste de Shapiro-Wilk - modelo de árvore de decisão\n",
        "\n",
        "#from scipy.stats import shapiro\n",
        "\n",
        "stat1, p1 = shapiro(ac_prev_arv)\n",
        "stat2, p2 = shapiro(prec_cat1_arv)\n",
        "stat3, p3 = shapiro(prec_cat2_arv)\n",
        "stat4, p4 = shapiro(rec_cat1_arv)\n",
        "stat5, p5 = shapiro(rec_cat2_arv)\n",
        "stat6, p6 = shapiro(f1_cat1_arv)\n",
        "stat7, p7 = shapiro(f1_cat2_arv)\n",
        "\n",
        "print('Métrica, estatística teste do teste de Shapiro-Wilk (alfa = 0,05) e valor p:', '\\n')\n",
        "print('Acurácia de previsão:', round(stat1, 3), round(p1, 3))\n",
        "print('Precisão categoria 1:', round(stat2, 3), round(p2, 3))\n",
        "print('Precisão categoria 1:', round(stat3, 3), round(p3, 3))\n",
        "print('Recall categoria 1:', round(stat4, 3), round(p4, 3))\n",
        "print('Recall categoria 2:', round(stat5, 3), round(p5, 3))\n",
        "print('f1-score categoria 1:', round(stat6, 3), round(p6, 3))\n",
        "print('f1-score categoria 2:', round(stat7, 3), round(p7, 3))"
      ],
      "metadata": {
        "id": "ZhHs7CG24vkT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9rce-8LnOgSz"
      },
      "outputs": [],
      "source": [
        "#GridSearchCV - Floresta randômica\n",
        "\n",
        "param = {'criterion': ['gini', 'entropy'], \n",
        "            'n_estimators': [150, 250, 350],\n",
        "            'min_samples_split': range(1, 5), \n",
        "            'min_samples_leaf': range(1, 5)}\n",
        "\n",
        "G = GridSearchCV(estimator=RandomForestClassifier(), param_grid=param, cv = 10, verbose = 1, n_jobs = -1)\n",
        "G.fit(X_train, y_train)\n",
        "\n",
        "print('Os melhores parâmetros são', G.best_params_)\n",
        "print('O score de acurácia de treinamento é', G.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QdVrqSdHccyg"
      },
      "outputs": [],
      "source": [
        "#Algoritmo de Floresta Randômica\n",
        "\n",
        "#Cálculo das métricas do modelo de floresta randômica\n",
        "ac_trein = []\n",
        "ac_prev = []\n",
        "prec_cat1 = []\n",
        "prec_cat2 = []\n",
        "rec_cat1 = []\n",
        "rec_cat2 = []\n",
        "f1_cat1 = []\n",
        "f1_cat2 = []\n",
        "\n",
        "for i in range(0,100):\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X_vinhos_p_sub, y_vinhos_sub, test_size = 0.30)\n",
        "  RF = RandomForestClassifier(n_estimators=150, criterion = 'entropy', random_state=3, min_samples_leaf = 1, min_samples_split = 2)\n",
        "  RF.fit(X_train, y_train)\n",
        "  y_pred = RF.predict(X_test)\n",
        "  cm = confusion_matrix(y_test, y_pred)\n",
        "  ac_trein.append(RF.score(X_train, y_train))\n",
        "  ac_prev.append(accuracy_score(y_test, y_pred))\n",
        "  prec_cat1.append(cm[0, 0]/(cm[0, 0] + cm[1, 0]))\n",
        "  prec_cat2.append(cm[1, 1]/(cm[1, 1] + cm[0, 1]))\n",
        "  rec_cat1.append(cm[0, 0]/(cm[0, 0] + cm[0, 1]))\n",
        "  rec_cat2.append(cm[1, 1]/(cm[1, 1] + cm[1, 0]))\n",
        "  f1_cat1.append(2*((cm[0, 0]/(cm[0, 0] + cm[1, 0])) * (cm[0, 0]/(cm[0, 0] + cm[0, 1])))/\n",
        "                 ((cm[0, 0]/(cm[0, 0] + cm[1, 0])) + (cm[0, 0]/(cm[0, 0] + cm[0, 1]))))\n",
        "  f1_cat2.append(2*((cm[1, 1]/(cm[1, 1] + cm[0, 1])) * (cm[1, 1]/(cm[1, 1] + cm[1, 0])))/\n",
        "                 ((cm[1, 1]/(cm[1, 1] + cm[0, 1])) + (cm[1, 1]/(cm[1, 1] + cm[1, 0]))))\n",
        "\n",
        "print('Acurácia de treinamento:', round(np.mean(ac_trein), 3), '+/-', round(np.std(ac_trein), 3))\n",
        "print('Acurácia de previsão:', round(np.mean(ac_prev), 3), '+/-', round(np.std(ac_prev), 3))\n",
        "print('Precisão da categoria 1:', round(np.mean(prec_cat1), 3), '+/-', round(np.std(prec_cat1), 3))\n",
        "print('Precisão da categoria 2:', round(np.mean(prec_cat2), 3), '+/-', round(np.std(prec_cat2), 3))\n",
        "print('Recall da categoria 1:', round(np.mean(rec_cat1), 3), '+/-', round(np.std(rec_cat1), 3))\n",
        "print('Recall da categoria 2:', round(np.mean(rec_cat2), 3), '+/-', round(np.std(rec_cat2), 3))\n",
        "print('f1-score da categoria 1:', round(np.mean(f1_cat1), 3), '+/-', round(np.std(f1_cat1), 3))\n",
        "print('f1-score da categoria 2:', round(np.mean(f1_cat2), 3), '+/-', round(np.std(f1_cat2), 3))\n",
        "\n",
        "ac_prev_RF = np.copy(ac_prev)\n",
        "prec_cat1_RF = np.copy(prec_cat1)\n",
        "prec_cat2_RF = np.copy(prec_cat2)\n",
        "rec_cat1_RF = np.copy(rec_cat1)\n",
        "rec_cat2_RF = np.copy(rec_cat2)\n",
        "f1_cat1_RF = np.copy(f1_cat1)\n",
        "f1_cat2_RF = np.copy(f1_cat2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Histogramas - Floresta randômica\n",
        "\n",
        "fig, hi = plt.subplots(1, 4, figsize=(20, 8))\n",
        "hi[0].hist(x=ac_prev_RF, bins='auto', color='lightblue', alpha=0.9, rwidth=0.85); hi[0].set_title('acurácia de previsão')\n",
        "hi[1].hist(x=prec_cat1_RF, bins='auto', color='lightblue', alpha=0.9, rwidth=0.85); hi[1].set_title('precisão categoria 1')\n",
        "hi[2].hist(x=prec_cat2_RF, bins='auto', color='lightblue', alpha=0.9, rwidth=0.85); hi[2].set_title('precisão categoria 2')\n",
        "hi[3].hist(x=rec_cat1_RF, bins='auto', color='lightblue', alpha=0.9, rwidth=0.85); hi[3].set_title('recall categoria 1')\n",
        "\n",
        "fig, hi2 = plt.subplots(1, 3, figsize=(20, 8))\n",
        "hi2[0].hist(x=rec_cat2_RF, bins='auto', color='lightblue', alpha=0.9, rwidth=0.85); hi2[0].set_title('recall categoria 2')\n",
        "hi2[1].hist(x=f1_cat1_RF, bins='auto', color='lightblue', alpha=0.9, rwidth=0.85); hi2[1].set_title('f1-score categoria 1')\n",
        "hi2[2].hist(x=f1_cat2_RF, bins='auto', color='lightblue', alpha=0.9, rwidth=0.85); hi2[2].set_title('f1-score categoria 2')"
      ],
      "metadata": {
        "id": "-OKy2y0k81xz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Aplicação do teste de Shapiro-Wilk - modelo de floresta randômica\n",
        "\n",
        "stat1, p1 = shapiro(ac_prev_RF)\n",
        "stat2, p2 = shapiro(prec_cat1_RF)\n",
        "stat3, p3 = shapiro(prec_cat2_RF)\n",
        "stat4, p4 = shapiro(rec_cat1_RF)\n",
        "stat5, p5 = shapiro(rec_cat2_RF)\n",
        "stat6, p6 = shapiro(f1_cat1_RF)\n",
        "stat7, p7 = shapiro(f1_cat2_RF)\n",
        "\n",
        "print('Métrica, estatística teste do teste de Shapiro-Wilk (alfa = 0,05) e valor p:', '\\n')\n",
        "print('Acurácia de previsão:', round(stat1, 3), round(p1, 3))\n",
        "print('Precisão categoria 1:', round(stat2, 3), round(p2, 3))\n",
        "print('Precisão categoria 1:', round(stat3, 3), round(p3, 3))\n",
        "print('Recall categoria 1:', round(stat4, 3), round(p4, 3))\n",
        "print('Recall categoria 2:', round(stat5, 3), round(p5, 3))\n",
        "print('f1-score categoria 1:', round(stat6, 3), round(p6, 3))\n",
        "print('f1-score categoria 2:', round(stat7, 3), round(p7, 3))"
      ],
      "metadata": {
        "id": "OCUlcPLQ9Lvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sw7gT4cVmrRx"
      },
      "outputs": [],
      "source": [
        "#GridSearchCV - Redes Neurais Artificiais\n",
        "\n",
        "param = {'max_iter': [10000], \n",
        "            'hidden_layer_sizes': [(110, 110), (300)],\n",
        "            'activation': ['relu', 'logistic', 'tanh'],\n",
        "            'solver': ['adam', 'sgd']}\n",
        "\n",
        "G = GridSearchCV(neural_network.MLPClassifier(random_state=8), param_grid=param, cv = 10, verbose = 1, n_jobs = -1)\n",
        "y_prev = G.fit(X_train, y_train).predict(X_test)\n",
        "\n",
        "print('\\nOs melhores parâmetros são', G.best_params_)\n",
        "print('O score de acurácia de treinamento é', G.best_score_, '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eH2BycuGvou_"
      },
      "outputs": [],
      "source": [
        "#Algoritmo de Redes Neurais Artificiais\n",
        "\n",
        "#Cálculo das métricas do modelo de redes neurais artificiais\n",
        "ac_trein = []\n",
        "ac_prev = []\n",
        "prec_cat1 = []\n",
        "prec_cat2 = []\n",
        "rec_cat1 = []\n",
        "rec_cat2 = []\n",
        "f1_cat1 = []\n",
        "f1_cat2 = []\n",
        "\n",
        "for i in range(0, 100):\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X_vinhos_p_sub, y_vinhos_sub, test_size = 0.30)\n",
        "  RN = MLPClassifier(activation = 'relu', max_iter = 10000, hidden_layer_sizes= (110, 110), solver = 'adam', random_state=7)\n",
        "  RN.fit(X_train, y_train)\n",
        "  y_pred = RN.predict(X_test)\n",
        "  cm = confusion_matrix(y_test, y_pred)\n",
        "  ac_trein.append(RN.score(X_train, y_train))\n",
        "  ac_prev.append(accuracy_score(y_test, y_pred))\n",
        "  prec_cat1.append(cm[0, 0]/(cm[0, 0] + cm[1, 0]))\n",
        "  prec_cat2.append(cm[1, 1]/(cm[1, 1] + cm[0, 1]))\n",
        "  rec_cat1.append(cm[0, 0]/(cm[0, 0] + cm[0, 1]))\n",
        "  rec_cat2.append(cm[1, 1]/(cm[1, 1] + cm[1, 0]))\n",
        "  f1_cat1.append(2*((cm[0, 0]/(cm[0, 0] + cm[1, 0])) * (cm[0, 0]/(cm[0, 0] + cm[0, 1])))/\n",
        "                 ((cm[0, 0]/(cm[0, 0] + cm[1, 0])) + (cm[0, 0]/(cm[0, 0] + cm[0, 1]))))\n",
        "  f1_cat2.append(2*((cm[1, 1]/(cm[1, 1] + cm[0, 1])) * (cm[1, 1]/(cm[1, 1] + cm[1, 0])))/\n",
        "                 ((cm[1, 1]/(cm[1, 1] + cm[0, 1])) + (cm[1, 1]/(cm[1, 1] + cm[1, 0]))))\n",
        "\n",
        "print('Acurácia de treinamento:', round(np.mean(ac_trein), 3), '+/-', round(np.std(ac_trein), 3))\n",
        "print('Acurácia de previsão:', round(np.mean(ac_prev), 3), '+/-', round(np.std(ac_prev), 3))\n",
        "print('Precisão da categoria 1:', round(np.mean(prec_cat1), 3), '+/-', round(np.std(prec_cat1), 3))\n",
        "print('Precisão da categoria 2:', round(np.mean(prec_cat2), 3), '+/-', round(np.std(prec_cat2), 3))\n",
        "print('Recall da categoria 1:', round(np.mean(rec_cat1), 3), '+/-', round(np.std(rec_cat1), 3))\n",
        "print('Recall da categoria 2:', round(np.mean(rec_cat2), 3), '+/-', round(np.std(rec_cat2), 3))\n",
        "print('f1-score da categoria 1:', round(np.mean(f1_cat1), 3), '+/-', round(np.std(f1_cat1), 3))\n",
        "print('f1-score da categoria 2:', round(np.mean(f1_cat2), 3), '+/-', round(np.std(f1_cat2), 3))\n",
        "\n",
        "ac_prev_RN = np.copy(ac_prev)\n",
        "prec_cat1_RN = np.copy(prec_cat1)\n",
        "prec_cat2_RN = np.copy(prec_cat2)\n",
        "rec_cat1_RN = np.copy(rec_cat1)\n",
        "rec_cat2_RN = np.copy(rec_cat2)\n",
        "f1_cat1_RN = np.copy(f1_cat1)\n",
        "f1_cat2_RN = np.copy(f1_cat2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Histogramas - Redes Neurais Artificiais\n",
        "\n",
        "fig, hi = plt.subplots(1, 4, figsize=(20, 8))\n",
        "hi[0].hist(x=ac_prev_RN, bins='auto', color='lightblue', alpha=0.9, rwidth=0.85); hi[0].set_title('acurácia de previsão')\n",
        "hi[1].hist(x=prec_cat1_RN, bins='auto', color='lightblue', alpha=0.9, rwidth=0.85); hi[1].set_title('precisão categoria 1')\n",
        "hi[2].hist(x=prec_cat2_RN, bins='auto', color='lightblue', alpha=0.9, rwidth=0.85); hi[2].set_title('precisão categoria 2')\n",
        "hi[3].hist(x=rec_cat1_RN, bins='auto', color='lightblue', alpha=0.9, rwidth=0.85); hi[3].set_title('recall categoria 1')\n",
        "\n",
        "fig, hi2 = plt.subplots(1, 3, figsize=(20, 8))\n",
        "hi2[0].hist(x=rec_cat2_RN, bins='auto', color='lightblue', alpha=0.9, rwidth=0.85); hi2[0].set_title('recall categoria 2')\n",
        "hi2[1].hist(x=f1_cat1_RN, bins='auto', color='lightblue', alpha=0.9, rwidth=0.85); hi2[1].set_title('f1-score categoria 1')\n",
        "hi2[2].hist(x=f1_cat2_RN, bins='auto', color='lightblue', alpha=0.9, rwidth=0.85); hi2[2].set_title('f1-score categoria 2')"
      ],
      "metadata": {
        "id": "_51GtLoF_10e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Aplicação do teste de Shapiro-Wilk - modelo de redes neurais artificiais\n",
        "\n",
        "from scipy.stats import shapiro\n",
        "\n",
        "stat1, p1 = shapiro(ac_prev_RN)\n",
        "stat2, p2 = shapiro(prec_cat1_RN)\n",
        "stat3, p3 = shapiro(prec_cat2_RN)\n",
        "stat4, p4 = shapiro(rec_cat1_RN)\n",
        "stat5, p5 = shapiro(rec_cat2_RN)\n",
        "stat6, p6 = shapiro(f1_cat1_RN)\n",
        "stat7, p7 = shapiro(f1_cat2_RN)\n",
        "\n",
        "print('Métrica, estatística teste do teste de Shapiro-Wilk (alfa = 0,05) e valor p:', '\\n')\n",
        "print('Acurácia de previsão:', round(stat1, 3), round(p1, 3))\n",
        "print('Precisão categoria 1:', round(stat2, 3), round(p2, 3))\n",
        "print('Precisão categoria 1:', round(stat3, 3), round(p3, 3))\n",
        "print('Recall categoria 1:', round(stat4, 3), round(p4, 3))\n",
        "print('Recall categoria 2:', round(stat5, 3), round(p5, 3))\n",
        "print('f1-score categoria 1:', round(stat6, 3), round(p6, 3))\n",
        "print('f1-score categoria 2:', round(stat7, 3), round(p7, 3))"
      ],
      "metadata": {
        "id": "gYdni6cDAY3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#GridSearchCV - adaboost\n",
        "\n",
        "abc = AdaBoostClassifier(base_estimator=DecisionTreeClassifier())\n",
        "\n",
        "param = {'base_estimator__max_depth': [10, 20],\n",
        "              'base_estimator__min_samples_leaf': [3, 5],\n",
        "              'n_estimators': [350, 450],\n",
        "              'learning_rate': [0.01, 0.1]}\n",
        "\n",
        "classif = GridSearchCV(abc, param, verbose=1, n_jobs=-1, cv = 10)\n",
        "classif.fit(X_train,y_train)\n",
        "y_prev = classif.fit(X_train, y_train).predict(X_test)\n",
        "\n",
        "print('\\nOs melhores parâmetros são', classif.best_params_)\n",
        "print('O score de acurácia de treinamento é', classif.best_score_, '\\n')"
      ],
      "metadata": {
        "id": "i_pH1trYrVlw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rthGm1-ETYUQ"
      },
      "outputs": [],
      "source": [
        "#Gerando o classificador adaboost\n",
        "\n",
        "#Cálculo das métricas do adaboost\n",
        "ac_trein = []\n",
        "ac_prev = []\n",
        "prec_cat1 = []\n",
        "prec_cat2 = []\n",
        "rec_cat1 = []\n",
        "rec_cat2 = []\n",
        "f1_cat1 = []\n",
        "f1_cat2 = []\n",
        "\n",
        "for i in range(0,100):\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X_vinhos_p_sub, y_vinhos_sub, test_size = 0.30)\n",
        "  classifier = AdaBoostClassifier(DecisionTreeClassifier(max_depth=20, min_samples_leaf=5), n_estimators=450, learning_rate=0.1)\n",
        "  model = classifier.fit(X_train, y_train)\n",
        "  y_pred = model.predict(X_test)\n",
        "  cm = confusion_matrix(y_test, y_pred)\n",
        "  ac_trein.append(classifier.score(X_train, y_train))\n",
        "  ac_prev.append(accuracy_score(y_test, y_pred))\n",
        "  prec_cat1.append(cm[0, 0]/(cm[0, 0] + cm[1, 0]))\n",
        "  prec_cat2.append(cm[1, 1]/(cm[1, 1] + cm[0, 1]))\n",
        "  rec_cat1.append(cm[0, 0]/(cm[0, 0] + cm[0, 1]))\n",
        "  rec_cat2.append(cm[1, 1]/(cm[1, 1] + cm[1, 0]))\n",
        "  f1_cat1.append(2*((cm[0, 0]/(cm[0, 0] + cm[1, 0])) * (cm[0, 0]/(cm[0, 0] + cm[0, 1])))/\n",
        "                 ((cm[0, 0]/(cm[0, 0] + cm[1, 0])) + (cm[0, 0]/(cm[0, 0] + cm[0, 1]))))\n",
        "  f1_cat2.append(2*((cm[1, 1]/(cm[1, 1] + cm[0, 1])) * (cm[1, 1]/(cm[1, 1] + cm[1, 0])))/\n",
        "                 ((cm[1, 1]/(cm[1, 1] + cm[0, 1])) + (cm[1, 1]/(cm[1, 1] + cm[1, 0]))))\n",
        "\n",
        "print('Acurácia de treinamento:', round(np.mean(ac_trein), 3), '+/-', round(np.std(ac_trein), 3))\n",
        "print('Acurácia de previsão:', round(np.mean(ac_prev), 3), '+/-', round(np.std(ac_prev), 3))\n",
        "print('Precisão da categoria 1:', round(np.mean(prec_cat1), 3), '+/-', round(np.std(prec_cat1), 3))\n",
        "print('Precisão da categoria 2:', round(np.mean(prec_cat2), 3), '+/-', round(np.std(prec_cat2), 3))\n",
        "print('Recall da categoria 1:', round(np.mean(rec_cat1), 3), '+/-', round(np.std(rec_cat1), 3))\n",
        "print('Recall da categoria 2:', round(np.mean(rec_cat2), 3), '+/-', round(np.std(rec_cat2), 3))\n",
        "print('f1-score da categoria 1:', round(np.mean(f1_cat1), 3), '+/-', round(np.std(f1_cat1), 3))\n",
        "print('f1-score da categoria 2:', round(np.mean(f1_cat2), 3), '+/-', round(np.std(f1_cat2), 3))\n",
        "\n",
        "ac_prev_ada = np.copy(ac_prev)\n",
        "prec_cat1_ada = np.copy(prec_cat1)\n",
        "prec_cat2_ada = np.copy(prec_cat2)\n",
        "rec_cat1_ada = np.copy(rec_cat1)\n",
        "rec_cat2_ada = np.copy(rec_cat2)\n",
        "f1_cat1_ada = np.copy(f1_cat1)\n",
        "f1_cat2_ada = np.copy(f1_cat2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Histogramas - adaboost\n",
        "\n",
        "fig, hi = plt.subplots(1, 4, figsize=(20, 8))\n",
        "hi[0].hist(x=ac_prev_ada, bins='auto', color='lightblue', alpha=0.9, rwidth=0.85); hi[0].set_title('acurácia de previsão')\n",
        "hi[1].hist(x=prec_cat1_ada, bins='auto', color='lightblue', alpha=0.9, rwidth=0.85); hi[1].set_title('precisão categoria 1')\n",
        "hi[2].hist(x=prec_cat2_ada, bins='auto', color='lightblue', alpha=0.9, rwidth=0.85); hi[2].set_title('precisão categoria 2')\n",
        "hi[3].hist(x=rec_cat1_ada, bins='auto', color='lightblue', alpha=0.9, rwidth=0.85); hi[3].set_title('recall categoria 1')\n",
        "\n",
        "fig, hi2 = plt.subplots(1, 3, figsize=(20, 8))\n",
        "hi2[0].hist(x=rec_cat2_ada, bins='auto', color='lightblue', alpha=0.9, rwidth=0.85); hi2[0].set_title('recall categoria 2')\n",
        "hi2[1].hist(x=f1_cat1_ada, bins='auto', color='lightblue', alpha=0.9, rwidth=0.85); hi2[1].set_title('f1-score categoria 1')\n",
        "hi2[2].hist(x=f1_cat2_ada, bins='auto', color='lightblue', alpha=0.9, rwidth=0.85); hi2[2].set_title('f1-score categoria 2')"
      ],
      "metadata": {
        "id": "UKjw5kgsA8iA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Aplicação do teste de Shapiro-Wilk - modelo adaboost\n",
        "\n",
        "from scipy.stats import shapiro\n",
        "\n",
        "stat1, p1 = shapiro(ac_prev_ada)\n",
        "stat2, p2 = shapiro(prec_cat1_ada)\n",
        "stat3, p3 = shapiro(prec_cat2_ada)\n",
        "stat4, p4 = shapiro(rec_cat1_ada)\n",
        "stat5, p5 = shapiro(rec_cat2_ada)\n",
        "stat6, p6 = shapiro(f1_cat1_ada)\n",
        "stat7, p7 = shapiro(f1_cat2_ada)\n",
        "\n",
        "print('Métrica, estatística teste do teste de Shapiro-Wilk (alfa = 0,05) e valor p:', '\\n')\n",
        "print('Acurácia de previsão:', round(stat1, 3), round(p1, 3))\n",
        "print('Precisão categoria 1:', round(stat2, 3), round(p2, 3))\n",
        "print('Precisão categoria 1:', round(stat3, 3), round(p3, 3))\n",
        "print('Recall categoria 1:', round(stat4, 3), round(p4, 3))\n",
        "print('Recall categoria 2:', round(stat5, 3), round(p5, 3))\n",
        "print('f1-score categoria 1:', round(stat6, 3), round(p6, 3))\n",
        "print('f1-score categoria 2:', round(stat7, 3), round(p7, 3))"
      ],
      "metadata": {
        "id": "ep5sgyjZBDx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#GridSearchCV - gradient boosting\n",
        "\n",
        "gbo = GradientBoostingClassifier()\n",
        "\n",
        "param2 = {'max_features': [7, 10], 'max_depth': [10, 13],\n",
        "          'n_estimators': [150, 200],\n",
        "          'learning_rate': [0.3, 0.4], \n",
        "          'min_samples_leaf': [6, 8]}\n",
        "\n",
        "classif2 = GridSearchCV(gbo, param2, verbose=1, n_jobs=-1, cv = 10)\n",
        "classif2.fit(X_train,y_train)\n",
        "y_prev = classif2.fit(X_train, y_train).predict(X_test)\n",
        "\n",
        "print('\\nOs melhores parâmetros são', classif2.best_params_)\n",
        "print('O score de acurácia de treinamento é', classif2.best_score_, '\\n')"
      ],
      "metadata": {
        "id": "ysUczMhjEYpv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2rT_D7kilkov"
      },
      "outputs": [],
      "source": [
        "# Geração do classificador gradient boosting\n",
        "\n",
        "#Cálculo das métricas do gradiente boosting\n",
        "ac_trein = []\n",
        "ac_prev = []\n",
        "prec_cat1 = []\n",
        "prec_cat2 = []\n",
        "rec_cat1 = []\n",
        "rec_cat2 = []\n",
        "f1_cat1 = []\n",
        "f1_cat2 = []\n",
        "\n",
        "for i in range(0,100):\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X_vinhos_p_sub, y_vinhos_sub, test_size = 0.30)\n",
        "  gb_clf = GradientBoostingClassifier(n_estimators=200, learning_rate=0.4, max_features=10, max_depth=13, min_samples_leaf=6)\n",
        "  model = gb_clf.fit(X_train, y_train)\n",
        "  y_pred = model.predict(X_test)\n",
        "  cm = confusion_matrix(y_test, y_pred)\n",
        "  ac_trein.append(classifier.score(X_train, y_train))\n",
        "  ac_prev.append(accuracy_score(y_test, y_pred))\n",
        "  prec_cat1.append(cm[0, 0]/(cm[0, 0] + cm[1, 0]))\n",
        "  prec_cat2.append(cm[1, 1]/(cm[1, 1] + cm[0, 1]))\n",
        "  rec_cat1.append(cm[0, 0]/(cm[0, 0] + cm[0, 1]))\n",
        "  rec_cat2.append(cm[1, 1]/(cm[1, 1] + cm[1, 0]))\n",
        "  f1_cat1.append(2*((cm[0, 0]/(cm[0, 0] + cm[1, 0])) * (cm[0, 0]/(cm[0, 0] + cm[0, 1])))/\n",
        "                 ((cm[0, 0]/(cm[0, 0] + cm[1, 0])) + (cm[0, 0]/(cm[0, 0] + cm[0, 1]))))\n",
        "  f1_cat2.append(2*((cm[1, 1]/(cm[1, 1] + cm[0, 1])) * (cm[1, 1]/(cm[1, 1] + cm[1, 0])))/\n",
        "                 ((cm[1, 1]/(cm[1, 1] + cm[0, 1])) + (cm[1, 1]/(cm[1, 1] + cm[1, 0]))))\n",
        "\n",
        "print('Acurácia de treinamento:', round(np.mean(ac_trein), 3), '+/-', round(np.std(ac_trein), 3))\n",
        "print('Acurácia de previsão:', round(np.mean(ac_prev), 3), '+/-', round(np.std(ac_prev), 3))\n",
        "print('Precisão da categoria 1:', round(np.mean(prec_cat1), 3), '+/-', round(np.std(prec_cat1), 3))\n",
        "print('Precisão da categoria 2:', round(np.mean(prec_cat2), 3), '+/-', round(np.std(prec_cat2), 3))\n",
        "print('Recall da categoria 1:', round(np.mean(rec_cat1), 3), '+/-', round(np.std(rec_cat1), 3))\n",
        "print('Recall da categoria 2:', round(np.mean(rec_cat2), 3), '+/-', round(np.std(rec_cat2), 3))\n",
        "print('f1-score da categoria 1:', round(np.mean(f1_cat1), 3), '+/-', round(np.std(f1_cat1), 3))\n",
        "print('f1-score da categoria 2:', round(np.mean(f1_cat2), 3), '+/-', round(np.std(f1_cat2), 3))\n",
        "\n",
        "ac_prev_gra = np.copy(ac_prev)\n",
        "prec_cat1_gra = np.copy(prec_cat1)\n",
        "prec_cat2_gra = np.copy(prec_cat2)\n",
        "rec_cat1_gra = np.copy(rec_cat1)\n",
        "rec_cat2_gra = np.copy(rec_cat2)\n",
        "f1_cat1_gra = np.copy(f1_cat1)\n",
        "f1_cat2_gra = np.copy(f1_cat2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Histogramas - gradient boosting\n",
        "\n",
        "fig, hi = plt.subplots(1, 4, figsize=(20, 8))\n",
        "hi[0].hist(x=ac_prev_gra, bins='auto', color='lightblue', alpha=0.9, rwidth=0.85); hi[0].set_title('acurácia de previsão')\n",
        "hi[1].hist(x=prec_cat1_gra, bins='auto', color='lightblue', alpha=0.9, rwidth=0.85); hi[1].set_title('precisão categoria 1')\n",
        "hi[2].hist(x=prec_cat2_gra, bins='auto', color='lightblue', alpha=0.9, rwidth=0.85); hi[2].set_title('precisão categoria 2')\n",
        "hi[3].hist(x=rec_cat1_gra, bins='auto', color='lightblue', alpha=0.9, rwidth=0.85); hi[3].set_title('recall categoria 1')\n",
        "  \n",
        "fig, hi2 = plt.subplots(1, 3, figsize=(20, 8))\n",
        "hi2[0].hist(x=rec_cat2_gra, bins='auto', color='lightblue', alpha=0.9, rwidth=0.85); hi2[0].set_title('recall categoria 2')\n",
        "hi2[1].hist(x=f1_cat1_gra, bins='auto', color='lightblue', alpha=0.9, rwidth=0.85); hi2[1].set_title('f1-score categoria 1')\n",
        "hi2[2].hist(x=f1_cat2_gra, bins='auto', color='lightblue', alpha=0.9, rwidth=0.85); hi2[2].set_title('f1-score categoria 2')"
      ],
      "metadata": {
        "id": "i9aQj7LUDgNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Aplicação do teste de Shapiro-Wilk - modelo gradient boosting\n",
        "\n",
        "from scipy.stats import shapiro\n",
        "\n",
        "stat1, p1 = shapiro(ac_prev_gra)\n",
        "stat2, p2 = shapiro(prec_cat1_gra)\n",
        "stat3, p3 = shapiro(prec_cat2_gra)\n",
        "stat4, p4 = shapiro(rec_cat1_gra)\n",
        "stat5, p5 = shapiro(rec_cat2_gra)\n",
        "stat6, p6 = shapiro(f1_cat1_gra)\n",
        "stat7, p7 = shapiro(f1_cat2_gra)\n",
        "\n",
        "print('Métrica, estatística teste do teste de Shapiro-Wilk (alfa = 0,05) e valor p:', '\\n')\n",
        "print('Acurácia de previsão:', round(stat1, 3), round(p1, 3))\n",
        "print('Precisão categoria 1:', round(stat2, 3), round(p2, 3))\n",
        "print('Precisão categoria 1:', round(stat3, 3), round(p3, 3))\n",
        "print('Recall categoria 1:', round(stat4, 3), round(p4, 3))\n",
        "print('Recall categoria 2:', round(stat5, 3), round(p5, 3))\n",
        "print('f1-score categoria 1:', round(stat6, 3), round(p6, 3))\n",
        "print('f1-score categoria 2:', round(stat7, 3), round(p7, 3))"
      ],
      "metadata": {
        "id": "KRgn_ahOD2kg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**APLICAÇÃO DOS TESTES DE HIPÓTESES**"
      ],
      "metadata": {
        "id": "0G81IUBNY1E-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ANOVA de 1 fator - acurácia de previsão\n",
        "\n",
        "#Geração do dataframe\n",
        "arv = [1]*100; RF = [2]*100; RN = [3]*100; ada = [4]*100; gra = [5]*100\n",
        "arv = pd.DataFrame(arv); RF = pd.DataFrame(RF); RN = pd.DataFrame(RN); ada = pd.DataFrame(ada); gra = pd.DataFrame(gra)\n",
        "ind = pd.concat([arv, RF, RN, ada, gra], ignore_index=1)\n",
        "\n",
        "ac_prev_arv = pd.DataFrame(ac_prev_arv)\n",
        "ac_prev_RF = pd.DataFrame(ac_prev_RF)\n",
        "ac_prev_RN = pd.DataFrame(ac_prev_RN)\n",
        "ac_prev_ada = pd.DataFrame(ac_prev_ada)\n",
        "ac_prev_gra = pd.DataFrame(ac_prev_gra)\n",
        "ac_prev_anova = pd.concat([ac_prev_arv, ac_prev_RF, ac_prev_RN, ac_prev_ada, ac_prev_gra], ignore_index=1)\n",
        "\n",
        "df_ANOVA = pd.concat([ind, ac_prev_anova], axis=1)\n",
        "df_ANOVA.columns = ['modelos', 'acur_prev']\n",
        "print(df_ANOVA, '\\n')\n",
        "\n",
        "# Tabela Anova (1 fator)\n",
        "model = ols('acur_prev ~ C(modelos)', data=df_ANOVA).fit()\n",
        "anova_table = sm.stats.anova_lm(model, typ=2)\n",
        "print('> Tabela ANOVA (1 fator):')\n",
        "print(anova_table, '\\n')\n",
        "\n",
        "#Teste de Tukey\n",
        "tuk = pairwise_tukeyhsd(endog=df_ANOVA['acur_prev'], groups=df_ANOVA['modelos'], alpha=0.05)\n",
        "print('> Tabela do teste de Tukey:')\n",
        "print(tuk)"
      ],
      "metadata": {
        "id": "zkjL4l5v4lVP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ANOVA de 1 fator - precisão da categoria 1 do atributo classe\n",
        "\n",
        "#Geração do dataframe\n",
        "\n",
        "#objeto ind gerado previamente nos processamentos do modelo de árvore de decisão\n",
        "prec_cat1_arv = pd.DataFrame(prec_cat1_arv)\n",
        "prec_cat1_RF = pd.DataFrame(prec_cat1_RF)\n",
        "prec_cat1_RN = pd.DataFrame(prec_cat1_RN)\n",
        "prec_cat1_ada = pd.DataFrame(prec_cat1_ada)\n",
        "prec_cat1_gra = pd.DataFrame(prec_cat1_gra)\n",
        "prec_cat1_anova = pd.concat([prec_cat1_arv, prec_cat1_RF, prec_cat1_RN, prec_cat1_ada, prec_cat1_gra], ignore_index=1)\n",
        "\n",
        "df_ANOVA = pd.concat([ind, prec_cat1_anova], axis=1)\n",
        "df_ANOVA.columns = ['modelos', 'precisao_cat1']\n",
        "print(df_ANOVA, '\\n')\n",
        "\n",
        "#Tabela Anova (1 fator)\n",
        "model = ols('precisao_cat1 ~ C(modelos)', data=df_ANOVA).fit()\n",
        "anova_table = sm.stats.anova_lm(model, typ=2)\n",
        "print('> Tabela ANOVA (1 fator):')\n",
        "print(anova_table, '\\n')\n",
        "\n",
        "#Teste de Tukey\n",
        "tuk = pairwise_tukeyhsd(endog=df_ANOVA['precisao_cat1'], groups=df_ANOVA['modelos'], alpha=0.05)\n",
        "print('> Tabela do teste de Tukey:')\n",
        "print(tuk)"
      ],
      "metadata": {
        "id": "FN-ivUQS4Taa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ANOVA de 1 fator - precisão da categoria 2 do atributo classe\n",
        "\n",
        "#Geração do dataframe\n",
        "\n",
        "#objeto ind gerado previamente nos processamentos do modelo de árvore de decisão\n",
        "prec_cat2_arv = pd.DataFrame(prec_cat2_arv)\n",
        "prec_cat2_RF = pd.DataFrame(prec_cat2_RF)\n",
        "prec_cat2_RN = pd.DataFrame(prec_cat2_RN)\n",
        "prec_cat2_ada = pd.DataFrame(prec_cat2_ada)\n",
        "prec_cat2_gra = pd.DataFrame(prec_cat2_gra)\n",
        "prec_cat2_anova = pd.concat([prec_cat2_arv, prec_cat2_RF, prec_cat2_RN, prec_cat2_ada, prec_cat2_gra], ignore_index=1)\n",
        "\n",
        "df_ANOVA = pd.concat([ind, prec_cat2_anova], axis=1)\n",
        "df_ANOVA.columns = ['modelos', 'precisao_cat2']\n",
        "print(df_ANOVA, '\\n')\n",
        "\n",
        "#Tabela Anova (1 fator)\n",
        "model = ols('precisao_cat2 ~ C(modelos)', data=df_ANOVA).fit()\n",
        "anova_table = sm.stats.anova_lm(model, typ=2)\n",
        "print('> Tabela ANOVA (1 fator):')\n",
        "print(anova_table, '\\n')\n",
        "\n",
        "#Teste de Tukey\n",
        "tuk = pairwise_tukeyhsd(endog=df_ANOVA['precisao_cat2'], groups=df_ANOVA['modelos'], alpha=0.05)\n",
        "print('> Tabela do teste de Tukey:')\n",
        "print(tuk)"
      ],
      "metadata": {
        "id": "lkkn3poC6yDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ANOVA de 1 fator - revocação da categoria 1 do atributo classe\n",
        "\n",
        "#Geração do dataframe\n",
        "\n",
        "#objeto ind gerado previamente nos processamentos do modelo de árvore de decisão\n",
        "rec_cat1_arv = pd.DataFrame(rec_cat1_arv)\n",
        "rec_cat1_RF = pd.DataFrame(rec_cat1_RF)\n",
        "rec_cat1_RN = pd.DataFrame(rec_cat1_RN)\n",
        "rec_cat1_ada = pd.DataFrame(rec_cat1_ada)\n",
        "rec_cat1_gra = pd.DataFrame(rec_cat1_gra)\n",
        "rec_cat1_anova = pd.concat([rec_cat1_arv, rec_cat1_RF, rec_cat1_RN, rec_cat1_ada, rec_cat1_gra], ignore_index=1)\n",
        "\n",
        "df_ANOVA = pd.concat([ind, rec_cat1_anova], axis=1)\n",
        "df_ANOVA.columns = ['modelos', 'recall_cat1']\n",
        "print(df_ANOVA, '\\n')\n",
        "\n",
        "#Tabela Anova (1 fator)\n",
        "model = ols('recall_cat1 ~ C(modelos)', data=df_ANOVA).fit()\n",
        "anova_table = sm.stats.anova_lm(model, typ=2)\n",
        "print('> Tabela ANOVA (1 fator):')\n",
        "print(anova_table, '\\n')\n",
        "\n",
        "#Teste de Tukey\n",
        "tuk = pairwise_tukeyhsd(endog=df_ANOVA['recall_cat1'], groups=df_ANOVA['modelos'], alpha=0.05)\n",
        "print('> Tabela do teste de Tukey:')\n",
        "print(tuk)"
      ],
      "metadata": {
        "id": "he2ZfZki7mqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ANOVA de 1 fator - revocação da categoria 2 do atributo classe\n",
        "\n",
        "#Geração do dataframe\n",
        "\n",
        "#objeto ind gerado previamente nos processamentos do modelo de árvore de decisão\n",
        "rec_cat2_arv = pd.DataFrame(rec_cat2_arv)\n",
        "rec_cat2_RF = pd.DataFrame(rec_cat2_RF)\n",
        "rec_cat2_RN = pd.DataFrame(rec_cat2_RN)\n",
        "rec_cat2_ada = pd.DataFrame(rec_cat2_ada)\n",
        "rec_cat2_gra = pd.DataFrame(rec_cat2_gra)\n",
        "rec_cat2_anova = pd.concat([rec_cat2_arv, rec_cat2_RF, rec_cat2_RN, rec_cat2_ada, rec_cat2_gra], ignore_index=1)\n",
        "\n",
        "df_ANOVA = pd.concat([ind, rec_cat2_anova], axis=1)\n",
        "df_ANOVA.columns = ['modelos', 'recall_cat2']\n",
        "print(df_ANOVA, '\\n')\n",
        "\n",
        "#Tabela Anova (1 fator)\n",
        "model = ols('recall_cat2 ~ C(modelos)', data=df_ANOVA).fit()\n",
        "anova_table = sm.stats.anova_lm(model, typ=2)\n",
        "print('> Tabela ANOVA (1 fator):')\n",
        "print(anova_table, '\\n')\n",
        "\n",
        "#Teste de Tukey\n",
        "tuk = pairwise_tukeyhsd(endog=df_ANOVA['recall_cat2'], groups=df_ANOVA['modelos'], alpha=0.05)\n",
        "print('> Tabela do teste de Tukey:')\n",
        "print(tuk)"
      ],
      "metadata": {
        "id": "JktO-S9F8RP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ANOVA de 1 fator - f1-score da categoria 1 do atributo classe\n",
        "\n",
        "#Geração do dataframe\n",
        "\n",
        "#objeto ind gerado previamente nos processamentos do modelo de árvore de decisão\n",
        "f1_cat1_arv = pd.DataFrame(f1_cat1_arv)\n",
        "f1_cat1_RF = pd.DataFrame(f1_cat1_RF)\n",
        "f1_cat1_RN = pd.DataFrame(f1_cat1_RN)\n",
        "f1_cat1_ada = pd.DataFrame(f1_cat1_ada)\n",
        "f1_cat1_gra = pd.DataFrame(f1_cat1_gra)\n",
        "f1_cat1_anova = pd.concat([f1_cat1_arv, f1_cat1_RF, f1_cat1_RN, f1_cat1_ada, f1_cat1_gra], ignore_index=1)\n",
        "\n",
        "df_ANOVA = pd.concat([ind, f1_cat1_anova], axis=1)\n",
        "df_ANOVA.columns = ['modelos', 'f1score_cat1']\n",
        "print(df_ANOVA, '\\n')\n",
        "\n",
        "#Tabela Anova (1 fator)\n",
        "model = ols('f1score_cat1 ~ C(modelos)', data=df_ANOVA).fit()\n",
        "anova_table = sm.stats.anova_lm(model, typ=2)\n",
        "print('> Tabela ANOVA (1 fator):')\n",
        "print(anova_table, '\\n')\n",
        "\n",
        "#Teste de Tukey\n",
        "tuk = pairwise_tukeyhsd(endog=df_ANOVA['f1score_cat1'], groups=df_ANOVA['modelos'], alpha=0.05)\n",
        "print('> Tabela do teste de Tukey:')\n",
        "print(tuk)"
      ],
      "metadata": {
        "id": "nKR5tqXn8rd7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ANOVA de 1 fator - f1-score da categoria 2 do atributo classe\n",
        "\n",
        "#Geração do dataframe\n",
        "\n",
        "#objeto ind gerado previamente nos processamentos do modelo de árvore de decisão\n",
        "f1_cat2_arv = pd.DataFrame(f1_cat2_arv)\n",
        "f1_cat2_RF = pd.DataFrame(f1_cat2_RF)\n",
        "f1_cat2_RN = pd.DataFrame(f1_cat2_RN)\n",
        "f1_cat2_ada = pd.DataFrame(f1_cat2_ada)\n",
        "f1_cat2_gra = pd.DataFrame(f1_cat2_gra)\n",
        "f1_cat2_anova = pd.concat([f1_cat2_arv, f1_cat2_RF, f1_cat2_RN, f1_cat2_ada, f1_cat2_gra], ignore_index=1)\n",
        "\n",
        "df_ANOVA = pd.concat([ind, f1_cat2_anova], axis=1)\n",
        "df_ANOVA.columns = ['modelos', 'f1score_cat2']\n",
        "print(df_ANOVA, '\\n')\n",
        "\n",
        "#Tabela Anova (1 fator)\n",
        "model = ols('f1score_cat2 ~ C(modelos)', data=df_ANOVA).fit()\n",
        "anova_table = sm.stats.anova_lm(model, typ=2)\n",
        "\n",
        "print('> Tabela ANOVA (1 fator):')\n",
        "print(anova_table, '\\n')\n",
        "\n",
        "#Teste de Tukey\n",
        "tuk = pairwise_tukeyhsd(endog=df_ANOVA['f1score_cat2'], groups=df_ANOVA['modelos'], alpha=0.05)\n",
        "print('> Tabela do teste de Tukey:')\n",
        "print(tuk)"
      ],
      "metadata": {
        "id": "0UGfaFIk9RpT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jwsdTa07VQC8"
      },
      "outputs": [],
      "source": [
        "#Processamento único do algoritmo de redes neurais artificiais\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_vinhos_p_sub, y_vinhos_sub, test_size = 0.30)\n",
        "\n",
        "RN = MLPClassifier(activation = 'relu', max_iter = 10000, hidden_layer_sizes= (110, 110), solver = 'adam', random_state=7)\n",
        "RN.fit(X_train, y_train)\n",
        "y_pred = RN.predict(X_test)\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "cmd = ConfusionMatrixDisplay(cm, display_labels=['Categoria 1', 'Categoria 2'])\n",
        "cmd.plot()\n",
        "cmd.ax_.set(xlabel='Previsto', ylabel='Verdadeiro')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "vinhos.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}